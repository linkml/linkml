[tool.linkml]
# inject a schema map into the top-level __init__.py file to discover
# schema sources and yaml files.
include_schemas = true
# or, for namespace packages...
# include_schemas = [
#   package_name
# ]

[tool.linkml.schema]
# define a mapping between short IDs and paths
# ideally these would match the `id` of the schema, but whatever.
my_schema = "path/from/root.yaml"
other_schema = "different/path.yaml"

[tool.linkml.generate]
# settings for individual generator for all schema
pythongen.enabled = true
owlgen.enabled = true

[tool.linkml.generate.global]
# global settings that apply to all generators (if applicable)

# can use jinja template strings, and the context has
# ``schema`` : the SchemaDefinition
# ``generator`` : the instantiated generator class
output = "path/{{ schema.version }}/{{ schema.name }}.{{ generator.file_extension }} "

[tool.linkml.generate.pydantic]
# equivalent to `pythongen.enabled = true` syntax above but expanded...
enable = false
# set additional defaults whether globally enabled for the `build` command or not,
# defaults are used when doing `linkml generate {generator}`
meta = "full"
# override global defaults
output = "path/otherpath/pydantic/{{ schema.name }}.py"

[tool.linkml.build.my_schema]
# enable generators with default settings
excelgen.enable = true
csvgen.enable = true

[tool.linkml.build.my_schema.pydanticgen]
# customize specific generator for a specific schema
enable = true
output = "specific/path.py"

# can use pre-build and post-build hooks.
# pre-build hooks receive the schema and the build config model if they
# request them in the function signature
pre_build = "mypackage.module:function"
# by default "type" is "module", but can also call shell scripts
post_build = {type = "shell", value="black {{ config.output }}" }
# or python code
# post_build = { type = "python", value='''
# with open({{ config.output }}, 'r') as f:
#     print(f.read())
# ''' }